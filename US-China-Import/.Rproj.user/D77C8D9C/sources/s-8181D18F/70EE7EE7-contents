---
title: "HW3 Combined"
output: word_document
---

```{r Setup, include=FALSE, results='hide', warning=FALSE}

# Package setup
if(!require("pacman")) install.packages("pacman")

pacman::p_load(car, here, tidyverse, dplyr, ggplot2, data.table, lubridate, glmnet, stargazer, forecast, lmtest, hwwntest)
```

# Problem 1

1. This problem involves examination of monthly Lydia Pinkham data for the period
1938 through 1952. It addresses model construction and estimation of the 90 per cent
duration interval. The data are in Lydiamonthly.txt.

```{r}
m.sales <- read.csv("Lydiamonthly.txt")

Time <- seq(1, nrow(m.sales))
fMonth<-as.factor(m.sales$month)
logmsales <- log(m.sales$msales)

m.sales<-data.frame(m.sales, Time, fMonth, logmsales)

attach(m.sales)
```


(a) Construct a model relating sales and advertising with sales as the response. Explore
the inclusion of lagged sales and lagged advertising variables. Include estimation of
seasonal structure, dummies for outliers, and necessary calendar variables. Describe your
fitted model.

## Problem 1.a.1

Construct a model relating sales and advertising with sales as the response.

**Discussion:** An initial inspection of model1 suggests that AR3 model is a good place to start. 

```{r}
model1<-lm(msales~madv)
summary(model1)
```
```{r}
forecast::tsdisplay(resid(model1))
```

## Problem 1.a.2

Explore the inclusion of lagged sales and lagged advertising variables. Include estimation of
seasonal structure, dummies for outliers, and necessary calendar variables. Describe your
fitted model.

**Discussion:** First we fit an AR(3) model with the inclusion of following X variables: advertising, lagged advertising, all dummy fmonth variables, all dummy outlier variables, and all calendar pairs.

The initial residual plot is not flat, and while the autocorrelation plot shows that there remains significant autocorrelation in the model at lag 28, the lags are largely within the blue lines. The spectrum analysis of the residuals show that the model has been reduced to white noise (as indicated by the blue line measurement). The AIC of this model is 3965.163.

We now discuss the significance of the variables.

**Lag Variables:** The initial summary indicates that AR3 (msalesl3) has marginal significance. We will try AR(2) model next.

**X Variables:**
The preliminary summary below indicates that lagged advertising variables 2, 3, and 4 have marginal significance. We will try reducing the number to 2 lagged advertising variables (including madvl1 and madvl2).

The fMonth dummy variables seem to be significant, will have to conduct a partial f-test to confirm this. Some of the calendar pairs do not seem to be significant and we have to individually inspect their significance through partial f-test. All the outliers seem to be significant, so we will keep them.

```{r}
model2 <- lm(msales~madv+madvl1+madvl2+madvl3+madvl4+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348+c432+s432)

summary(model2)
```
```{r}
res2 <- resid(model2)
resid2 <- ts(res2) #,start=c(1992,1),freq=12)
plot(resid2, xlab="time",ylab="residuals",main="Residuals of Model 2")
```
``` {r}
acf(ts(res2), 37)
```
```{r}
spectrum(res2, span=3)
abline(v=c(1/12,2/12,3/12,4/12,5/12,6/12),col="red",lty=2)
abline(v=c(0.348,0.432),col="blue",lty=2)
```
```{r}
AIC(model2)

```
**Discussion:** This model 3 shows a little bit of improvement in terms of AIC: the AIC IS now 3961.624, down from 3965.16 previously. This is in part due to the reduction of lagged advertising variables (we include in model3 only the first two lagged advertising variables compared to all four lagged advertising variables in the previous model).

The summary shows that madvl2 has marginal significance in this model. We conducted anova test to see the significance of madvl1 and madvl2 together, and they show a marginal significance of .1195. This suggests that madvl2 may not be necessary. We will exclude it in our next fit.

```{r}
model3 <- lm(msales~madv+madvl1+madvl2+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348+c432+s432)

summary(model3)
```
```{r}
res3 <- resid(model3)
resid3 <- ts(res3) #,start=c(1992,1),freq=12)
plot(resid3, xlab="time",ylab="residuals",main="Residuals of Model 3")
```
``` {r}
acf(ts(res3), 37)
```
```{r}
spectrum(res3, span=3)
abline(v=c(1/12,2/12,3/12,4/12,5/12,6/12),col="red",lty=2)
abline(v=c(0.348,0.432),col="blue",lty=2)
```
```{r}
AIC(model3)
```
```{r}
model3.1 <- lm(msales~madv+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348+c432+s432)

anova(model3.1, model3)
```

**Discussion:** In this model we exclude the variable madvl2 and noticed an improvement in AIC from 3161.62 to 3960.17. The advertising and lagged advertising variables are now shown to be significant. Next we conduct partial f-test to test the significance of fMonth and calendar pair variables.

```{r}
model4 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348+c432+s432)

summary(model4)
```

```{r}
AIC(model4)
```

**Partial F-test testing the significance of fMonth variables**

**Discussion:** Partial f-tests below indicate that fMonth variables are significant.

```{r}
model5.1 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348+c432+s432)

model5.2 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+feb44+dec44+jan45+sep45+c348+c220+s220+s348+c432+s432)

anova(model5.2, model5.1)
```

**Partial F-test testing the significance of calendar pair variables**

**Discussion:** Partial f-tests below indicate that calendar pairs 220, 348, and 432 have significances of .05286, 0.05859, and 0.7798 respectively. Based on this we can remove the 432 pair. After removing the pair, the AIC improves to 3956.76 from 3960.17

```{r}
model5.3 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c348+s348+c432+s432)

anova(model5.3, model5.1)
```
```{r}
model5.4 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c432+s432)

anova(model5.4, model5.1)
```

```{r}
model5.5 <- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348)

anova(model5.5, model5.1)
```

```{r}
model6<- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348)

AIC(model6)
```
**final model**

The final model includes as variables:
  - contemporary advertising
  - lag 1 advertising variables (madvl1)
  - all the lag sales variables (msalesl1-msalesl3)
  - the fmonth dummy variables to account for seasonality
  - all four outlier variables(feb44, dec44, jan45, sep45)
  - calendar pairs 220 and 348
  
We conduct a final partial f-test to determine the significance of lagged advertising variables (madvl2, madvl3, madvl4) and the test concludes that they do not Granger-cause msales with p-value of 0.8088.

A look at the seasonal indices plot indicate that, annually and on average, sales drop in April to June and rises from August to October before dropping in November and December. Thereafter sales would pick up in January to March before dropping in April.

```{r}
model6<- lm(msales~madv+madvl1+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348)

model6.1<- lm(msales~madv+madvl1+madvl2+madvl3+madvl4+msalesl1+msalesl2+msalesl3+fMonth+feb44+dec44+jan45+sep45+c220+s220+c348+s348)

anova(model6.1, model6)
```
``` {r}
b1<-coef(model6)[1]
b2<-coef(model6)[7:17]+b1
b3<-c(b1,b2)
seas<-b3-mean(b3)

seas.ts<-ts(seas)
seas
seas.ts
plot(seas.ts,ylab="seasonal indices",xlab="month")
```


## Problem 1.b.1

Analyze the residuals from your model. Give a normal quantile plot, plot the
residuals vs. time, present the residual autocorrelations and partial autocorrelations, and
produce the residual spectral density plot. Discuss the results carefully.

**Discussion:** The qqplot indicates that normality has been roughly achieved, as most observations fall on the qqline. There are a few deviations at the tails, however they are a few compared to the the vast majority of observations which fall on the line.

The residuals plot show that it is largely flat and variance is relatively constant around the mean of 0. We cannot reject that homoscedacticity is not achieved based on this plot.

The ACF and PACF plots show no significant autocorrelation except for lag 28 in the ACF plot. There are a few lags in the two plots which seem to reach the blue line but they do not excessively cross the line. I decided to leave them as is as they do not constitute a major issue for the model.

The residual spectral density plot indicates that white noise reduction has been achieved as the distance between highest and lowest peaks of the plot is less than twice the length of the blue measurement line above the notch.

```{r}
res6 <- resid(model6)
```

**normal quantile plot**

```{r}
qqnorm(res6)
qqline(res6)
```

**plot the residuals vs. time**

```{r}
plot(ts(res6), xlab="time",ylab="residuals",main="Residuals of Model 6")
```

**present the residual autocorrelations and partial autocorrelations** 

``` {r}
acf(ts(res6), 37)
```
``` {r}
pacf(ts(res6))
```

**produce the residual spectral density plot**

```{r}
spectrum(res6, span=3)
abline(v=c(1/12,2/12,3/12,4/12,5/12,6/12),col="red",lty=2)
abline(v=c(0.348,0.432),col="blue",lty=2)
```
```{r}
summary(model6)
```



## Problem 1.c

Calculate the estimate of the 90 per cent duration interval and discuss the result.

**Discussion:** The calculation below shows a 90% duration interval of 6.10 years. This indicates that current advertising continues to have an impact upon sales for approximately 6.10 years.

```{r}
summary(model6)
```

St = 20920 + 0.4458St-1 + 0.2766St-2 + 0.1202St-3 +  0.2296At + .08894At-1 + ...

(1 – 0.4458BSt-1 - 0.2766B^2St-2 - 0.1202B^3St-3) St = 20920 + 0.2296At + .08894At-1 + ...

St = 
  (1 – 0.4458BSt-1 - 0.2766B^2St-2 - 0.1202B^3St-3)^-1 * 21030 + 
  (1 – 0.4458BSt-1 - 0.2766B^2St-2 - 0.1202B^3St-3)^-1 * (0.2296 + .08894B)At + ...


We have a case where p = 3, r = 1, so p >= r,

Now we calculate deltas

delta0 = .2296
delta1 = .08894 + (0.4458 * .2296) = .1913


```{r}
deltapartial<-delta<-c(rep(0,times=500))
#deltapartial is the partial sum of the deltas
delta[1]<-0.2296
delta[2]<-0.1913

deltapartial[1]<-delta[1]
deltapartial[2]<-deltapartial[1]+delta[2]
for(j in 3:500){
j1<-j-1;j2<-j-2
delta[j]<-0.4458*delta[j1]+0.2766*delta[j2]
deltapartial[j]<-deltapartial[j1]+delta[j]
}

deltapartial[500]*0.9
```

```{r}
deltapartial[1:20]
```

90 percent duration interval = 2 + (1.033 - .4209) / (.570 - .4209) = 6.10

# Problem 2

The file qconsumption2.txt contains quarterly data measuring U.S. Real Personal
Consumption Expenditures percentage changes for the period 1953.1 to 2019.4. The data
are seasonally adjusted.

```{r}
consumption <- read.csv("qconsumption2.txt")
attach(consumption)
```

(a) Work with the data spanning the period 1953.1 to 2007.4.

(i) Plot the data vs. time and discuss features of the plot. Give a list of the economic
downturns as determined by the Business Cycle Dating Committee of NBER. Can you
relate these recessions to movements in the plot?

**Discussion:** Personal consumption expenditures percentage changes drop during recessions. Recession periods are highlighted in orange below and as we can see, percent changes consistently drops during recession periods. 

Personal consumption expenditures percentage changes are mostly positive from 1953 to 2007, the only exception being negative percentage changes during most of the highlighted recession periods. This indicates that recession largely drives consumers to reduce their personal consumption expenditures.

```{r echo=FALSE}
# we manually input the contraction periods from NBER. 
cycle <- data.frame(from = c('1945-01-01','1948-10-01','1953-07-01','1957-07-01','1960-04-01','1970-01-01','1973-10-01','1980-01-01','1981-07-01','1990-07-01','2001-04-01','2008-01-01','2020-03-01'),
                    to = c('1945-10-01','1949-10-01','1954-04-01','1958-04-01','1961-01-01','1970-10-01','1975-04-01','1980-07-01','1982-10-01','1991-04-01','2001-10-01','2009-07-01','2020-04-01'))
```


```{r echo=FALSE}
# we create a new column "rects" which signals 1 if it row corresponds to a "recession" period according to NEBR data

lst <- rep(0, nrow(consumption))
consumption$rects <-lst

consumption<-transform(consumption,rects=ifelse(Quarter %in% cycle$from,1,rects))
consumption<-transform(consumption,rects=ifelse(Quarter %in% cycle$to,2,rects))

for (i in seq(2, nrow(consumption), by=1)) {
  if (consumption$rects[i] == 0) {
    if (consumption$rects[i-1] == 1) {
       consumption$rects[i] <- 1
    }
  }
}

consumption<-transform(consumption,rects=ifelse(rects==2,1,rects))
```

```{r echo=FALSE}
consumption <- consumption %>% mutate(Time = 1:n())
```

```{r echo=FALSE}
# take the span of 1953.1 to 2007.4
consumption.a <- consumption %>% slice(1:220)
```

```{r echo=FALSE}
set.seed(0)
dat <- consumption.a

## Determine highlighted regions
v <- dat$rects

## Get the start and end points for highlighted regions
inds <- diff(c(0, v))
#print(v)
start <- dat$Time[inds == 1]
end <- dat$Time[inds == -1]
if (length(start) > length(end)) end <- c(end, tail(dat$Time, 1))

## highlight region data
rects <- data.frame(start=start, end=end, group=seq_along(start))

ggplot(data=dat, aes(Time, Pctchange)) +
theme_minimal() +
geom_line(color = "#00AFBB", size = .5) +
geom_rect(data=rects, inherit.aes=FALSE, aes(xmin=start, xmax=end, ymin=min(dat$Pctchange),
ymax=max(dat$Pctchange), group=group), color="transparent", fill="orange", 
alpha=0.3) +
labs(title = "U.S. Real Personal
Consumption Expenditures Percentage Changes (Quarterly)", subtitle = "(From 1953 to 2007 - Contraction period highlighted in Orange)") 
```

(ii) Begin by identifying outliers and form dummies for them. [Form the dummies to
have length 220, so they cover the time span from 1953.1 to 2007.4.]

```{r}
jan58<-rep(0, nrow(consumption.a))
oct65<-rep(0, nrow(consumption.a))
oct74<-rep(0, nrow(consumption.a))
apr80<-rep(0, nrow(consumption.a))

jan58[21] <- 1
oct65[52] <- 1
oct74[88] <- 1
apr80[110] <- 1

consumption.a$jan58 <- jan58
consumption.a$oct65 <- oct65
consumption.a$oct74 <- oct74
consumption.a$apr80 <- apr80
```

(iii) An ARX model has the form. Then R commands to
fit such a model to the percentage changes, if the chosen order of the AR structure is p,
are as follows:

df<-data.frame(d1,d2)
arxmodel<-arima(Pctchange.ts[1:220],order=c(p,0,0),xreg=df)

Fit an ARX model to the data covering the period 1953.1 to 2007.4. Explain how you
arrived at your model fit.

**Discussion:** The initial ACF suggests MA(3) and PACF suggests AR(2) are good places to start.

```{r}
pctchange.ts<-ts(consumption.a$Pctchange)
forecast::tsdisplay(pctchange.ts)
```
**Discussion:** We fit MA(3) and AR(2) models below, including the outliers. Both models show that white noise reduction was successfully achieved, however MA(3) has better/smaller AIC than AR(2) (AIC is 1009.97 for MA(3) and 1019.01 for AR(2)). Both models show that all four of the outlier variables are statistically significant.

We next try an ARMA(2,3), and MA(4) and AR(3) for comparison.

```{r}
outliers<- consumption.a %>% select(jan58, oct65,oct74,apr80)
outliers<- as.matrix(outliers)
MA3<-Arima(pctchange.ts,order=c(0,0,3), xreg=outliers)
AR2<-Arima(pctchange.ts,order=c(2,0,0), xreg=outliers)
```

MA(3) analysis

```{r}
summary(MA3)
```
```{r}
checkresiduals(MA3)
```
```{r}
coeftest(MA3)
```
AR2 analysis

```{r}
summary(AR2)
```

```{r}
checkresiduals(AR2)
```
```{r}
coeftest(AR2)
```

**Discussion:** MA(3) still is the best fit with the smallest AIC of 1009.97 after fitting ARMA(2,3), MA(4), and AR(3), with AICs of 1011.2, 1011.96, 1020.87 respectively. We see also in MA(4) and AR(3) that the added lags in each model are insignificant and thus overfit. We can now confidently use MA(3).


```{r}
ARMA23<-Arima(pctchange.ts,order=c(2,0,3), xreg=outliers)
MA4<-Arima(pctchange.ts,order=c(0,0,4), xreg=outliers)
AR3<-Arima(pctchange.ts,order=c(3,0,0), xreg=outliers)
```

```{r}
summary(ARMA23)
checkresiduals(ARMA23)
coeftest(ARMA23)
```

```{r}
summary(MA4)
checkresiduals(MA4)
coeftest(MA4)
```

```{r}
summary(AR3)
checkresiduals(AR3)
coeftest(AR3)
```

(iv) Examine the residuals to investigate whether your selected model has achieved
reduction to white noise. For this purpose include in your discussion consideration of the
residual autocorrelations and partial autocorrelations and the residual spectral density.
Also examine and discuss the plot of the residuals vs. time. Perform Bartlett’s test to
determine if the fit has produced reduction to white noise. [Bartlett’s test is described
and its use is illustrated in the 28 March notes.]

**Discussion:** The ACF, PACF, and spectrum plots all indicate that the MA(3) model has been reduced to white noise. The ACF and PACF plots show no significant lag (all lags are within the blue lines) and the spectrum analysis shows that the highest and lowest peaks are well within the blue line above the notch. 

The residuals show constant variance over time, and there is no significant autocorrelation structure that can be seen in the residuals.

Bartlett's test shows that the model has been reduced to white noise. With a p-value of 0.9949, we cannot reject the null hypothesis that MA(3) fit has been reduced to white noise.

```{r}
forecast::tsdisplay(resid(MA3))
```
```{r}
spectrum(resid(MA3))
```
```{r}
bartlettB.test(ts(resid(MA3)))
```

(v) Find the zeros of the autoregressive polynomial for your model fit and interpret the
results.

**Discussion:** Since we chose an MA(3) model we find first the autoregressive form of the model by calculating deltas. The amplitude of complex zeros is 0.4477, which suggests that the presence of cycle is weak as it is closer to 0 than 1. The zeros of the autoregressive polynomial suggests the presence of a weak cycle of length about 15.45 quarters. This corresponds to peaks in the estimated spectral density at approximately 1/15.45 = 0.0647 cycles per quarter.

```{r}
coef(MA3)
```
```{r}
delta<-c(rep(0,times=10))
delta[1]<-1
delta[2]<--0.1875751

for(j in 3:10){
j1<-j-1
j2<-j-2
delta[j]<-- 0.1875751*delta[j1]-0.3568942*delta[j2]
}

delta
```

```{r}
# choosing delta[1:4] because MA(3) model has 3 coefficients
zeros<-1/polyroot(delta[1:4])
zeros
```

```{r}
#amplitude. Selecting zero with positive imaginary part.
Mod(zeros[3])
#period
2*pi/Arg(zeros)[3]
```


(b) Repeat the analysis in part (a) for the full time period in the data set, 1953.1 to
2019.4. Note that now the time series spans 268 quarters.

(i) Plot the data vs. time and discuss features of the plot. Give a list of the economic
downturns as determined by the Business Cycle Dating Committee of NBER. Can you
relate these recessions to movements in the plot?

**Discussion:** The extended plot now includes the 2008-2009 recession period and in it tthe percentage change of personal consumption expenditures are negative, a continuation of the pattern previously seen in the 1953-2007 analysis. As previously stated, this means consumers spend less on personal consumption during recession periods.

```{r echo=FALSE}
set.seed(0)
dat <- consumption

## Determine highlighted regions
v <- dat$rects

## Get the start and end points for highlighted regions
inds <- diff(c(0, v))
#print(v)
start <- dat$Time[inds == 1]
end <- dat$Time[inds == -1]
if (length(start) > length(end)) end <- c(end, tail(dat$Time, 1))

## highlight region data
rects <- data.frame(start=start, end=end, group=seq_along(start))

ggplot(data=dat, aes(Time, Pctchange)) +
theme_minimal() +
geom_line(color = "#00AFBB", size = .5) +
geom_rect(data=rects, inherit.aes=FALSE, aes(xmin=start, xmax=end, ymin=min(dat$Pctchange),
ymax=max(dat$Pctchange), group=group), color="transparent", fill="orange", 
alpha=0.3) +
labs(title = "U.S. Real Personal
Consumption Expenditures Percentage Changes (Quarterly)", subtitle = "(From 1953 to 2019 - Contraction period highlighted in Orange)") 
```
(ii) Begin by identifying outliers and form dummies for them. [Form the dummies to
have length 220, so they cover the time span from 1953.1 to 2007.4.]

**Discussion:** There are no new outliers that can be immediately seen from the plot. We do see a new low point during the 2009 recession but the drop is not so dramatic, as indicated by the percentage change points which is still over -5 (the previous outliers have percentage change points of either less than -5 or greater than 10). If our residuals later indicate that it is indeed an outlier we can refit.

```{r}
jan58<-rep(0, nrow(consumption))
oct65<-rep(0, nrow(consumption))
oct74<-rep(0, nrow(consumption))
apr80<-rep(0, nrow(consumption))

jan58[21] <- 1
oct65[52] <- 1
oct74[88] <- 1
apr80[110] <- 1

consumption$jan58 <- jan58
consumption$oct65 <- oct65
consumption$oct74 <- oct74
consumption$apr80 <- apr80
```

(iii) An ARX model has the form. Then R commands to
fit such a model to the percentage changes, if the chosen order of the AR structure is p,
are as follows:

Fit an ARX model to the data covering the period 1953.1 to 2007.4. Explain how you
arrived at your model fit.

**Discussion:** The initial ACF still suggests MA(3) fit to start, however now the PACF suggests AR(3) could be a better place to start instead of AR(2). We

```{r}
pctchange.ts.all<-ts(consumption$Pctchange)
forecast::tsdisplay(pctchange.ts.all)
```
**Discussion:** We fit MA(3) and AR(3) models below, including the outliers AND using the entire consumption dataset. Bartlett's test for both models show that white noise reduction was successfully achieved, however MA(3) has better/smaller AIC than AR(3) (AIC is 1202.46 for MA(3) and 1213.58 for AR(3)). Both models show that all four of the outlier variables are statistically significant.

The Coefficient test for AR(3) shows that it is an overfit model (the ar3 variable has a p-value of 0.35).

The ACF and PACF plot for the residuals of MA(3) model now shows that at lag 24 the line exceeds the blue threshold, however it is only slighlty exceeds the blue threshold so it is not necessarily critical that we add a variable to account for it.  

We next try an ARMA(3,3), and MA(4) and AR(2) for comparison and see if they may provide a better fit.

```{r}
outliers<- consumption %>% select(jan58, oct65,oct74,apr80)
outliers<- as.matrix(outliers)
MA3.all<-Arima(pctchange.ts.all,order=c(0,0,3), xreg=outliers)
AR3.all<-Arima(pctchange.ts.all,order=c(3,0,0), xreg=outliers)
```

MA(3).all analysis

```{r}
summary(MA3.all)
```
```{r}
checkresiduals(MA3.all)
```
```{r}
pacf(resid(MA3.all))
```


```{r}
coeftest(MA3.all)
```
```{r}
bartlettB.test(ts(resid(MA3.all)))
```

AR3.all analysis

```{r}
summary(AR3.all)
```

```{r}
checkresiduals(AR3.all)
```

```{r}
pacf(resid(AR3.all))
```

```{r}
coeftest(AR3.all)
```
```{r}
bartlettB.test(ts(resid(AR3.all)))
```

**Discussion:** MA(3) still is the best fit with the smallest AIC of 1202.46 after fitting ARMA(3,3), MA(4), and AR(2), with AICs of 1209.14, 1204.1, 1212.46 respectively. We see also in MA(4) that the added lags in the model are insignificant and thus overfit. MA(3) still has the smallest AIC so we will go forward in our analysis using this model.

```{r}
ARMA33.all<-Arima(pctchange.ts.all,order=c(3,0,3), xreg=outliers)
MA4.all<-Arima(pctchange.ts.all,order=c(0,0,4), xreg=outliers)
AR2.all<-Arima(pctchange.ts.all,order=c(2,0,0), xreg=outliers)
```

```{r}
summary(ARMA33.all)
checkresiduals(ARMA33.all)
coeftest(ARMA33.all)
```

```{r}
summary(MA4.all)
checkresiduals(MA4.all)
coeftest(MA4.all)
```

```{r}
summary(AR2.all)
checkresiduals(AR2.all)
coeftest(AR2.all)
```

(iv) Examine the residuals to investigate whether your selected model has achieved
reduction to white noise. For this purpose include in your discussion consideration of the
residual autocorrelations and partial autocorrelations and the residual spectral density.
Also examine and discuss the plot of the residuals vs. time. Perform Bartlett’s test to
determine if the fit has produced reduction to white noise. [Bartlett’s test is described
and its use is illustrated in the 28 March notes.]

**Discussion:** The ACF, PACF, and spectrum plots all indicate that the MA(3) model has been reduced to white noise. The ACF and PACF plots show some lag at lag 24 but it is not too significant. The spectrum analysis shows that the highest and lowest peaks are well within the blue line above the notch. 

The residuals show constant variance over time, and there is no significant autocorrelation structure that can be seen in the residuals. There may be is a bit of funneling of residuals at later periods but not to such an extent that we can confidently conclude presence of heteroscedacticity in the residuals.

Bartlett's test overwhelmingly shows that the model has been reduced to white noise with a p-value of 0.9999.

```{r}
forecast::tsdisplay(resid(MA3.all))
```
```{r}
spectrum(resid(MA3.all))
```

```{r}
bartlettB.test(ts(resid(MA3.all)))
```
(v) Find the zeros of the autoregressive polynomial for your model fit and interpret the
results.

**Discussion:** Since we chose an MA(3) model we find first the autoregressive form of the model by calculating deltas. The amplitude of complex zeros of the deltas is now 0.4968268, which suggests that the presence of cycle is weak as it is closer to 0 than 1. The zeros of the autoregressive polynomial suggests the presence of a weak cycle of length about 13.21 quarters. This corresponds to peaks in the estimated spectral density at approximately 1/15.45 = 0.0757 cycles per quarter.

```{r}
coef(MA3)
```

```{r}
coef(MA3.all)
```

```{r}
delta<-c(rep(0,times=10))
delta[1]<-1
delta[2]<--0.2257209

for(j in 3:10){
j1<-j-1
j2<-j-2
delta[j]<-- 0.2257209*delta[j1]-0.3850609*delta[j2]
}

delta
```

```{r}
# choosing delta[1:4] because MA(3) model has 3 coefficients
zeros<-1/polyroot(delta[1:4])
zeros
```

```{r}
#amplitude. Selecting zero with positive imaginary part.
Mod(zeros[3])
#period
2*pi/Arg(zeros)[3]
```


(c) The quarterly percentage changes for 2020.1 to 2021.4 were −6.9, −33.4, 41.4, 3.4,
11.4, 12.0, 2.0, and 3.1. Comment briefly on the implications of these numbers.

**Discussion:** The introduction of these numbers to fit a model may lead to sub-optimal models. The four previously identified outliers are percentage changes of values of -5.4, 11.7, -5.7, and -8.7. If we use the same standard in selecting these outliers (less than -5 and greater than 10), then five percentage change values from 2020.1 to 2021.4 would classify as outliers (−6.9, −33.4, 41.4, 11.4, 12.0). Two values in particular, -33.4 and 41.4, are vastly different from anything we have seen from 1953.1 to 2019.4, where most percentage changes fall between -5.0 and 10.0. These numbers has the potential to distort the model fitted and should be excluded.


